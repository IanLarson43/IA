import lightgbm as lgb
import numpy as np

matchups_file = np.load("data/matchups.npz")
winner_file = np.load("data/winner.npz")

# Start of code generated by ChatGPT
params = {
    "objective": "binary",
    "metric": "binary_logloss",
    "learning_rate": 0.03,
    "num_leaves": 63,
    "feature_fraction": 0.8,
    "bagging_fraction": 0.8,
    "bagging_freq": 1,
    "min_data_in_leaf": 20,
    "verbose": -1,
}
# End of code generated by ChatGPT

num_round = 2000

cat_indices = list(range(96))


def train(file_name):
    train_data = []
    train_result_data = []
    valid_data = []
    valid_result_data = []

    count = 0
    for match in matchups_file:
        if count < len(matchups_file) * 0.8:
            train_data.append(matchups_file[match])
            train_result_data.append(winner_file[match])
        else:
            valid_data.append(matchups_file[match])
            valid_result_data.append(winner_file[match])

        count += 1

    train_data = np.array(train_data)
    train_result_data = np.array(train_result_data)
    valid_data = np.array(valid_data)
    valid_result_data = np.array(valid_result_data)

    train_set = lgb.Dataset(
        train_data, label=train_result_data, categorical_feature=cat_indices
    )

    valid_set = lgb.Dataset(
        valid_data, label=valid_result_data, categorical_feature=cat_indices
    )

    bst = lgb.train(
        params,
        train_set,
        num_round,
        valid_sets=[valid_set],
        callbacks=[lgb.early_stopping(50)],
    )

    bst.save_model(f"models/{file_name}.txt")
